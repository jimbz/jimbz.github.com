<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jim Braux-Zin's homepage</title><link href="http://www.braux-zin.com/" rel="alternate"></link><link href="http://www.braux-zin.com/feeds/index.atom.xml" rel="self"></link><id>http://www.braux-zin.com/</id><updated>2013-10-28T00:00:00+01:00</updated><entry><title>Thesis</title><link href="http://www.braux-zin.com/index.html#thesis" rel="alternate"></link><updated>2013-10-28T00:00:00+01:00</updated><author><name>Jim Braux-Zin</name></author><id>tag:www.braux-zin.com,2013-10-28:index.html#thesis</id><summary type="html">&lt;p&gt;My thesis' goal is the design of an augmented reality system. This broad subject led me to two main directions.&lt;/p&gt;
&lt;h1 id="optical-see-through-augmented-reality"&gt;Optical-See-Through Augmented Reality&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Our optical see-through prototype" src="http://www.braux-zin.com/images/seethrough/system.jpg" /&gt;
Augmented Reality could be of great help for critical applications such as driving or surgery assistance. However in these cases every millisecond counts and the user cannot afford to add any latency to reality. This dismisses all &lt;em&gt;video see-through&lt;/em&gt; solutions for &lt;em&gt;optical see-through&lt;/em&gt; ones, where virtual augmentations are layered onto the reality thanks to a semi-transparent display. This adds new constraints on the system for proper alignment with reality. We focused on a tablet-like system composed of a transparent LCD screen and two localization devices (one to compute the pose relative to the environment and the other to locate the user). We believe this kind of systems would be more practical to the user (well-delimited window, no heavy head-mounted device) and the designer (less constraint on the weight, slower motion) relative to current head-mounted displays.&lt;/p&gt;
&lt;h1 id="combining-direct-and-feature-based-costs-for-optical-flow-and-stereovision"&gt;Combining Direct and Feature-Based Costs for Optical Flow and Stereovision&lt;/h1&gt;
&lt;p&gt;The estimation of a dense motion field (optical flow) is a very important building block for many computer vision tasks such as 3d reconstruction. We introduce a new framework allowing to leverage the information provided by sparse feature matches (point or segment) to guide a dense iterative optical flow estimation out of local minima. This allows to vastly increase the convergence basin without any loss of accuracy. A wide range of application is then possible, without modification, such as wide-baseline stereovision or non-rigid surface registration.&lt;/p&gt;
&lt;p class="standalone"&gt;&lt;img alt="Reference image" src="http://www.braux-zin.com/images/daisy/4.png" title="Reference image" /&gt; &lt;img alt="Second image" src="http://www.braux-zin.com/images/daisy/2.png" title="Second image" /&gt; &lt;img alt="Depth" src="http://www.braux-zin.com/images/daisy/42.png" title="Computed depth map with detected self-occlusions in green" /&gt;&lt;/p&gt;</summary></entry><entry><title>Bio/Resume</title><link href="http://www.braux-zin.com/index.html#bioresume" rel="alternate"></link><updated>2013-10-25T00:00:00+02:00</updated><author><name>Jim Braux-Zin</name></author><id>tag:www.braux-zin.com,2013-10-25:index.html#bioresume</id><summary type="html">&lt;p&gt;&lt;img alt="Profile picture" src="http://www.braux-zin.com/images/jim-braux-zin.jpg" /&gt;
Hi! My name is Jim and I am a French Ph.D. candidate in Computer Vision. I work at &lt;a href="http://www.kalisteo.fr/en/index.htm"&gt;CEA LIST&lt;/a&gt; under the supervision of &lt;a href="http://isit.u-clermont1.fr/~ab/"&gt;Adrien Bartoli&lt;/a&gt;. I am addressing exciting things such as augmented reality, 3d localization, 3d reconstruction and non-rigid surface registration.&lt;/p&gt;
&lt;h1 id="contact"&gt;Contact&lt;/h1&gt;
&lt;p&gt;You can add me on &lt;a href="https://plus.google.com/116983469368569043160"&gt;Google+&lt;/a&gt; to share news and thoughts about computer vision and technology. Feel free to contact me by &lt;a href="mailto:j.brauxzin@gmail.com"&gt;e-mail&lt;/a&gt; or &lt;a href="http://lnkd.in/2Ff7Ts"&gt;LinkedIn&lt;/a&gt;
&lt;script src="//platform.linkedin.com/in.js" type="text/javascript"&gt;&lt;/script&gt;
&lt;script type="IN/MemberProfile" data-id="http://www.linkedin.com/in/jimbz" data-format="hover" data-related="false"&gt;&lt;/script&gt;
.&lt;/p&gt;
&lt;h1 id="education"&gt;Education&lt;/h1&gt;
&lt;p&gt;I enrolled in a &lt;em&gt;double-degree&lt;/em&gt; Master's degree at &lt;a href="http://www.supelec.fr/374_p_14603/welcome.html"&gt;Supélec&lt;/a&gt; (Paris, France) and &lt;a href="http://www.kth.se/en"&gt;The Royal Institute of Technology (KTH)&lt;/a&gt; (Stockholm, Sweden). I majored in digital communications and signal processing with minors in robotics and computer vision. I was deeply implicated in student associative projects such as &lt;a href="http://enactus.org/"&gt;Enactus&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="skills"&gt;Skills&lt;/h1&gt;
&lt;h2 id="3d-computer-vision"&gt;3D Computer Vision&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Projective geometry&lt;/li&gt;
&lt;li&gt;Camera intrinsic and extrinsic calibration&lt;/li&gt;
&lt;li&gt;Simultaneous Localization And Mapping (SLAM)&lt;/li&gt;
&lt;li&gt;Sparse and dense 3d reconstruction&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="2d-computer-vision"&gt;2D Computer Vision&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Optical flow&lt;/li&gt;
&lt;li&gt;Stereovision&lt;/li&gt;
&lt;li&gt;Non-rigid surface registration&lt;/li&gt;
&lt;li&gt;Feature detection and matching (point and segment)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="continuous-optimization"&gt;Continuous Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Convex optimization (Gauss-Newton, Levenberg-Marquardt)&lt;/li&gt;
&lt;li&gt;Total Variation regularization&lt;/li&gt;
&lt;li&gt;Global optimization by Particle Swarm Optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="technical-skills"&gt;Technical skills&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Expert (+4 years)&lt;ul&gt;
&lt;li&gt;C++ (OpenCV, Eigen)&lt;/li&gt;
&lt;li&gt;General-purpose computing on graphics processing units (GPGPU) with CUDA&lt;/li&gt;
&lt;li&gt;Python (Numpy, Scipy, Matplotlib)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Advanced&lt;ul&gt;
&lt;li&gt;Matlab/Octave&lt;/li&gt;
&lt;li&gt;Qt framework&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;Android (OpenCV, JNI)&lt;/li&gt;
&lt;li&gt;Bash scripting&lt;/li&gt;
&lt;li&gt;Web development&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary></entry></feed>