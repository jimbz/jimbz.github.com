<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jim Braux-Zin's homepage</title><link href="http://www.braux-zin.com/" rel="alternate"></link><link href="http://www.braux-zin.com/feeds/all.atom.xml" rel="self"></link><id>http://www.braux-zin.com/</id><updated>2013-10-28T00:00:00+01:00</updated><entry><title>Research</title><link href="http://www.braux-zin.com/index.html#research" rel="alternate"></link><updated>2013-10-28T00:00:00+01:00</updated><author><name>Jim Braux-Zin</name></author><id>tag:www.braux-zin.com,2013-10-28:index.html#research</id><summary type="html">&lt;p&gt;The goal of my thesis is the design and implementation of an augmented reality system. This broad subject led me to two main directions.&lt;/p&gt;
&lt;h1 id="optical-see-through-augmented-reality"&gt;Optical-See-Through Augmented Reality&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Our optical see-through prototype" src="http://www.braux-zin.com/images/seethrough/system.jpg" /&gt;
Augmented Reality could be of great help for critical applications such as driving or surgery assistance. However in these cases every millisecond counts and the user cannot afford to add any latency to reality. This dismisses all &lt;em&gt;video see-through&lt;/em&gt; solutions for &lt;em&gt;optical see-through&lt;/em&gt; ones, where virtual augmentations are layered onto the reality thanks to a semi-transparent display. This adds new constraints on the system for proper alignment with reality. We focused on a tablet-like system composed of a transparent LCD screen and two localization devices (one to compute the pose relative to the environment and the other to locate the user). We believe this kind of systems would be more practical to the user (well-delimited window, no heavy head-mounted device) and the designer (less constraint on the weight, slower motion) relative to current head-mounted displays.&lt;/p&gt;
&lt;h1 id="combining-direct-and-feature-based-costs-for-optical-flow-and-stereovision"&gt;Combining Direct and Feature-Based Costs for Optical Flow and Stereovision&lt;/h1&gt;
&lt;p&gt;The estimation of a dense motion field (optical flow) is a very important building block for many computer vision tasks such as 3d reconstruction. We introduce a new framework allowing to leverage the information provided by sparse feature matches (point or segment) to guide a dense iterative optical flow estimation out of local minima. This allows to vastly increase the convergence basin without any loss of accuracy. A wide range of application is then possible, without modification, such as wide-baseline stereovision or non-rigid surface registration. Our method is one of the top ranking methods on the &lt;a href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow_detail.php?benchmark=flow&amp;amp;error=3&amp;amp;eval=all&amp;amp;result=5ca150bba490fec5afa8ee7beaeeed8f0fc585ac"&gt;KITTI&lt;/a&gt; benchmark.&lt;/p&gt;
&lt;p class="standalone"&gt;&lt;img alt="Wide-baseline stereo" src="http://www.braux-zin.com/images/dense_matching/daisy25.gif" style="width:auto;height:200px;" title="Wide-baseline stereo" /&gt; &lt;img alt="Wide-baseline non-rigid registration" src="http://www.braux-zin.com/images/dense_matching/michelle.gif" style="width:auto;height:200px;" title="Wide-baseline non-rigid registration" /&gt;&lt;/p&gt;</summary></entry><entry><title>Resume</title><link href="http://www.braux-zin.com/index.html#resume" rel="alternate"></link><updated>2013-10-25T00:00:00+02:00</updated><author><name>Jim Braux-Zin</name></author><id>tag:www.braux-zin.com,2013-10-25:index.html#resume</id><summary type="html">&lt;p&gt;&lt;img alt="Profile picture" src="http://www.braux-zin.com/images/jim-braux-zin.jpg" style="width:150px;border-radius:50%;" /&gt;
Hi! My name is Jim and I am a French Ph.D. candidate in Computer Vision. I work at &lt;a href="http://www.kalisteo.fr/en/index.htm"&gt;CEA LIST&lt;/a&gt; under the supervision of &lt;a href="http://isit.u-clermont1.fr/~ab/"&gt;Adrien Bartoli&lt;/a&gt;. I am addressing exciting things such as &lt;em&gt;augmented reality&lt;/em&gt;, &lt;em&gt;3d localization&lt;/em&gt;, &lt;em&gt;3d reconstruction&lt;/em&gt; and &lt;em&gt;non-rigid surface registration&lt;/em&gt;.
&lt;br/&gt;&lt;br/&gt;
I am expected to defend my thesis in &lt;strong&gt;june 2014&lt;/strong&gt;. I am mainly looking for exciting Computer Vision projects but I am open to any challenge, I would especially like to try my hand at some machine learning or big data applications. A full resume is available in &lt;a href="http://www.braux-zin.com/pdf/brauxzin_resume.pdf"&gt;English&lt;/a&gt; or in &lt;a href="http://www.braux-zin.com/pdf/brauxzin_cv.pdf"&gt;French&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="education"&gt;Education&lt;/h1&gt;
&lt;p&gt;I enrolled in a &lt;em&gt;double-degree&lt;/em&gt; Master's degree at &lt;a href="http://www.supelec.fr/374_p_14603/welcome.html"&gt;Supélec&lt;/a&gt; (Paris, France) and &lt;a href="http://www.kth.se/en"&gt;The Royal Institute of Technology (KTH)&lt;/a&gt; (Stockholm, Sweden). I majored in digital communications and signal processing with minors in robotics and computer vision. I was deeply involved in student associative projects such as &lt;a href="http://enactus.org/"&gt;Enactus&lt;/a&gt;.&lt;/p&gt;
&lt;section class="skills-section"&gt;
&lt;h1&gt;Scientific skills&lt;/h1&gt;

&lt;div class="skills"&gt;
&lt;h2&gt;3D Computer Vision&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Projective geometry&lt;/li&gt;
&lt;li&gt;Camera intrinsic and extrinsic calibration&lt;/li&gt;
&lt;li&gt;Simultaneous Localization And Mapping (SLAM)&lt;/li&gt;
&lt;li&gt;Sparse and dense 3d reconstruction&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class="skills"&gt;
&lt;h2&gt;2D Computer Vision&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Optical flow&lt;/li&gt;
&lt;li&gt;Stereovision&lt;/li&gt;
&lt;li&gt;Non-rigid surface registration&lt;/li&gt;
&lt;li&gt;Feature detection and matching (point and segment)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class="skills"&gt;
&lt;h2&gt;Continuous Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Convex optimization (Gauss&amp;#8209;Newton, Levenberg&amp;#8209;Marquardt)&lt;/li&gt;
&lt;li&gt;Total (Generalized) Variation regularization&lt;/li&gt;
&lt;li&gt;Global optimization by Particle Swarm Optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/section&gt;

&lt;section class="skills-section"&gt;
    &lt;h1&gt;Technical skills&lt;/h1&gt;
    &lt;div class="skills"&gt;
        &lt;h3&gt;Expert (&gt;4 years)&lt;/h3&gt;
        &lt;ul&gt;
        &lt;li&gt;C++ (OpenCV, Eigen)&lt;/li&gt;
        &lt;li&gt;GPGPU with CUDA&lt;/li&gt;
        &lt;li&gt;Python (Numpy, Scipy, Matplotlib)&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div class="skills"&gt;
        &lt;h3&gt;Advanced&lt;/h3&gt;
        &lt;ul&gt;
        &lt;li&gt;Matlab/Octave&lt;/li&gt;
        &lt;li&gt;Qt framework&lt;/li&gt;
        &lt;li&gt;Android (OpenCV, JNI)&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div class="skills"&gt;
        &lt;h3&gt; &lt;/h3&gt;
        &lt;ul&gt;
        &lt;li&gt;Blender (modelization and scripting)&lt;/li&gt;
        &lt;li&gt;Bash scripting&lt;/li&gt;
        &lt;li&gt;Web development&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/section&gt;</summary></entry></feed>